{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Streaming API of Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name: Cedric Bhihe\n",
      "Friends: 6\n",
      "\n",
      "Tweets received:\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +  +  +  +  +  +  +  +\n",
      " +  +  +"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-978d5e6233e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mtweetcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtwitter_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtwitter_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ArtificialIntelligence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Artificial Intelligence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/response.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/contrib/pyopenssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.pyc\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.pyc\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    406\u001b[0m             fd_events = _syscall_wrapper(self._epoll.poll, True,\n\u001b[1;32m    407\u001b[0m                                          \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                          maxevents=max_events)\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ckb/anaconda2/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.pyc\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, recalc_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_SYSCALL_SENTINEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# OSError is thrown by select.select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# IOError is thrown by select.epoll.poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "consumer_key = '__________________'\n",
    "consumer_secret = '__________________________'\n",
    "access_token = '________________________________________'\n",
    "access_secret = '__________________________________________'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "user = api.me()\n",
    "\n",
    "print('Name: ' + user.name)\n",
    "# print 'Name: {}'.format(user.name)\n",
    "# print('Location: ' + user.location)\n",
    "print('Friends: ' + str(user.followers_count))\n",
    "# print('Created: ' + str(user.created_at))\n",
    "# print('Description: ' + str(user.description))\n",
    "print \"\\nTweets received:\"\n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    " \n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            with open('ArtificialIntelligenceTweets.json', 'a') as f:\n",
    "                f.write(data)\n",
    "                global tweetcount\n",
    "                tweetcount += 1\n",
    "                if not(tweetcount%10):\n",
    "                    print \" +\"\n",
    "                else:\n",
    "                    print \" +\",\n",
    "                return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    " \n",
    "tweetcount = 0\n",
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.filter(track=['ArtificialIntelligence','Artificial Intelligence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Analizing tweets - Counting terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RT @clubdedatos: “A list of artificial intelligence tools you can use today — for personal use (1/3)” by @LiamHanel https://t.co/E6zDq7W5gY\n",
      "Can Artificial Intelligence Replace Executive Decision Making? via @mitsmr \n",
      "\n",
      "https://t.co/98wCa34v5m\n",
      "\n",
      "#AI #ML\n",
      "RT @ograsl Can Artificial Intelligence Replace Executive Decision Making? via @mitsmr \n",
      "\n",
      "https://t.co/msSosB0VIK\n",
      "\n",
      "#AI #ML\n",
      "RT @Ronald_vanLoon: SmartLiving or as we might live with artificial intelligence and an open IoT in a new reality | #IoT #Artificialin… \n",
      "RT @Ronald_vanLoon: SmartLiving or as we might live with artificial intelligence and an open IoT in a new reality | #IoT #Artificialin… \n",
      "RT @Ronald_vanLoon: Why Your Company Needs Data Translators | #Analytics #Artificialintelligence #RT https://t.co/Zd8qxpCVXt https://t.co/K…\n",
      "In 2018/2019, life will be much easier with Artificial Intelligence tech.\n",
      "RT @subhashishpaul: #Amazon ’s Echo Look is a minefield of #AI and privacy concerns https://t.co/5fefGzFBxR #artificialintelligence\n",
      "RT @evankirstel: Why we must prepare for the rise of the machines https://t.co/T2VvIIBIw2\n",
      "Norwegian.AI to launch €100 million fund to invest in artificial intelligence \n",
      "https://t.co/Yi5QhuS8lT\n",
      "\n",
      "via… https://t.co/FajZJG8X6S\n",
      "RT @Ronald_vanLoon: Why Your Company Needs Data Translators | #Analytics #Artificialintelligence #RT https://t.co/Zd8qxpCVXt https://t.co/K…\n",
      "RT @europestartup: Norwegian.AI to launch €100 million fund to invest in artificial intelligence \n",
      "https://t.co/Yi5QhuS8lT\n",
      "\n",
      "via… \n",
      "RT @Ronald_vanLoon: How Big Data Is Empowering AI and Machine Learning at Scale | #BigData #Artificialintelligence #RT… \n",
      "RT @homeAIinfo: Apple Just Acquired This Little-Known Artificial Intelligence Startup - Apple Just Acquired This Litt https://t.co/N9w7DVzV…\n",
      "Here’s The Unofficial Silicon Valley Explainer On Artificial Intelligence https://t.co/2XSnAiu9xE\n",
      "artificial intelligence(AI)      人工知能\n",
      "DUBIOUS ARTIFICIAL INTELLIGENCE IN THE WATER APPLE JACKS OF HORSE SEXT QUANTUM COMPUTING CANADA. YOUR TRAVEL COMPANION IS\n",
      "Perpetuating Bias: Why We Should Think Critically About Artificial Intelligence in Marketing https://t.co/zL3DUnqLel\n",
      "Advancing sex technologies \"Apple Just Acquired This Little-Known Artificial Intelligence Startup - Fortune\" https://t.co/cx8LCphWrQ\n",
      "RT @Ronald_vanLoon: How Big Data Is Empowering AI and Machine Learning at Scale | #BigData #Artificialintelligence #RT… \n",
      "RT @MadelineAshby: \"I'm not afraid OF artificial intelligence. I'm afraid FOR artificial intelligence.\" -- @tinysubversions @FIBERFestival\n",
      "RT @evankirstel: Why we must prepare for the rise of the machines https://t.co/T2VvIIBIw2\n",
      "Should cashiers be humans or machines?  https://t.co/q0yQdPD8dD #robots #robotics #ArtificialIntelligence #AI #startup\n",
      "RT @europestartup: Norwegian.AI to launch €100 million fund to invest in artificial intelligence \n",
      "https://t.co/Yi5QhuS8lT\n",
      "\n",
      "via… \n",
      "Sentiment Analysis Symposium 2017 - NYC, June 27+28 https://t.co/QqJUWrCG7w #MRX #ArtificialIntelligence… https://t.co/kKjQkTTIGu\n",
      "Canada: an increasingly appealing alternative for Artificial Intelligence https://t.co/5IjWqpGuMO @botler_ai… https://t.co/SHR4rhdMOB\n",
      "How law firms have been pioneering the use of artificial intelligence. #PredictiveCoding #eDiscovery #AI… https://t.co/VucZRexzhJ\n",
      "RT @Bitcoin_Bullet: https://t.co/ztqHIJqKl4 - Let's think about the future\n",
      "Artificial Intelligence - The Future - Ethics on AI &amp; more\n",
      "(… \n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup https://t.co/Ajaq8HgWKg #ai #ml #dl\n",
      "Artificial intelligence may not be that great, but I still prefer it to the world's natural stupidity\n",
      "RT @ivyleaguewriter: Will Artificial Intelligence Replace Manual Content Creation? https://t.co/Jzl37dQjF6 https://t.co/oVaQV8MIUo\n",
      "Should cashiers be humans or machines?  https://t.co/RdGC4kV5eQ #robots #robotics #ArtificialIntelligence #AI #startup\n",
      "Design In An Age of Artificial Intelligence – Startup Grind – Medium https://t.co/CB80WabQGj\n",
      "RT @tprstly: Apple Just Acquired This Little-Known Artificial Intelligence Startup - Fortune https://t.co/I1U80INlFe #ai https://t.co/FiTiU…\n",
      "#artificialintelligence https://t.co/9fC0JKZSDN\n",
      "\n",
      "Teaching robots to teach other robots\n",
      "RT @marcusborba: How Companies Are Already Using AI https://t.co/T5kWBKId7x #ArtificialIntelligence #DataScience #MachineLearning #AI https…\n",
      "Ronald van Loon: SmartLiving or as we might live with artificial intelligence and an open IoT in a new reality | #… https://t.co/lW8EgDuUrE\n",
      "RT @wiomax: #Bigdata and #machinelearning make compelling argument for #CyberSecurity https://t.co/pGOlN99cbD #DataAnalytics… \n",
      "Artificial intelligence may not be that great, but I still prefer it to natural, human stupidity\n",
      "Microsoft wants you to make cooler videos and is using artificial intelligence to help - CNBC https://t.co/xUX2RMK0l8\n",
      "RT @jlmico: #Dubai police launch #AI that can spot crimes before they happen: https://t.co/2rKBvnj0Lh #BigData #MachineLearning #Artificial…\n",
      "RT @Lumidatum: Can you trust insights from #ArtificialIntelligence?\n",
      "https://t.co/LQu9w92tBH #datascience #MachineLearning #CIO #CMO\n",
      "A Designer’s Guide To The $15 Billion #ArtificialIntelligence Industry - Artificial Intelligence https://t.co/iDLuqSXzrO\n",
      "RT @AEMarling: “Real stupidity beats artificial intelligence every time.” \n",
      "― Terry Pratchett\n",
      "RT @KhalidHamdan0: In the future, #ArtificialIntelligence will build on adoption enablers to unlock faster, smarter &amp; more intuitive a… \n",
      "RT @CIOStraightTalk: .@wadhwa, @CarnegieMellon :\"#AI is here and making amazing things possible\" #StraightTalk thoughts @MissDestructo ? ht…\n",
      "Artificial Intelligence and customer experience. The past, present and future according to @briansolis… https://t.co/atfeQZ0jml\n",
      "The era of Artificial Intelligence is here, but companies must combine this technology with business expertise https://t.co/tiqUca6JEG\n",
      "Perpetuating Bias: Why We Should Think Critically About Artificial Intelligence in Marketing #ai… https://t.co/GX3fxkR6eu\n",
      "#TheInterMind says Conscious Light is Data for the Conscious Mind. https://t.co/BXfRQY5coW #ArtificialIntelligence #AI #Consciousness\n",
      "“Cheat sheet of many neural network architectures {#artificialintelligence #deeplearning #machinelearning}… https://t.co/QaNiBRfqM4\n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup - Fortune #AIForEveryone #IAParaTodos https://t.co/KEoFUAwxe3\n",
      "RT @Ronald_vanLoon: The 10 Algorithms Machine Learning Engineers Need to Know | #MachineLearning #Artificialintelligence #RT… \n",
      "RT @_bernardofn: A Designer’s Guide To The $15 Billion #ArtificialIntelligence Industry - Artificial Intelligence https://t.co/iDLuqSXzrO\n",
      "#AI that generalizes from a situation it's been trained on to one where it hasn't. What could go wrong? https://t.co/6ihVkV7cWq\n",
      "RT @AxelHohl: Science Fiction Movies aka. KI, Matrix oder Klassiker wie 'Welt am Draht' waren schon nicht übel ... 'hach, das gut… \n",
      "Intelligent Agents: How Artificial Intelligence Fits Into #CRO https://t.co/xr7L44Z2xw https://t.co/Tw2IfDQVSj\n",
      "RT @Ronald_vanLoon: How Big Data Is Empowering AI and Machine Learning at Scale | #BigData #Artificialintelligence #RT… \n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup https://t.co/GDnRgFp2xw #ai #ml #dl\n",
      "RT @GrowthHackerSMB: Intelligent Agents: How Artificial Intelligence Fits Into #CRO https://t.co/xr7L44Z2xw https://t.co/Tw2IfDQVSj\n",
      "RT @FortuneMagazine: Apple just acquired this little-known artificial intelligence startup\n",
      "https://t.co/ohG3IUskJ2 https://t.co/CR8bNkzDgR\n",
      "RT @MikeQuindazzi: “Cheat sheet of many neural network architectures {#artificialintelligence #deeplearning #machinelearning}… \n",
      "RT @MikeQuindazzi: “Cheat sheet of many neural network architectures {#artificialintelligence #deeplearning #machinelearning}… \n",
      "RT @wef: Artificial intelligence will make or break us. Here's how we need to respond https://t.co/vuAHd0FQom #technology https://t.co/vsWz…\n",
      "RT @MikeQuindazzi: “Cheat sheet of many neural network architectures {#artificialintelligence #deeplearning #machinelearning}… \n",
      "RT @anabmap: We started new research @webfoundation on artificial intelligence. Are you or anyone you know working on #AI in #Kenya? Ping @…\n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup https://t.co/OqgmXv1OEO\n",
      "RT @Grocery_HQ: This artificial intelligence is designed to bring grocers future success @pathovertech.\n",
      "https://t.co/Vwmtqw1Pm6 https://t.c…\n",
      "RT @HEbertKONLABS: The era of Artificial Intelligence is here, but companies must combine this technology with business expertise https://t…\n",
      "RT @cloudpreacher: #AI revolution in #FinTech to transform the business financing market! #machinelearning #bigdata #ML… \n",
      "RT @evankirstel: Why we must prepare for the rise of the machines https://t.co/T2VvIIBIw2\n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup - Fortune https://t.co/ruMOzRp14d\n",
      "Apple Just Acquired This Little-Known Artificial Intelligence Startup - Fortune https://t.co/asrJtTz849\n",
      "RT @AEMarling: “Real stupidity beats artificial intelligence every time.” \n",
      "― Terry Pratchett\n",
      "Replacing a human worker with ArtificialIntelligence can only result in a local optimum in response quality.\n",
      "RT @cloudpreacher: #ArtificialIntelligence algorithms helping machines think: Collaborative Approach #AI Evolution!#ML… \n",
      "RT @MikeQuindazzi: “Cheat sheet of many neural network architectures {#artificialintelligence #deeplearning #machinelearning}… \n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "with open('ArtificialIntelligenceTweets.json','r') as json_file:\n",
    "         for line in json_file:\n",
    "             tweet = json.loads(line)\n",
    "             print tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @clubdedatos: “A list of artificial intelligence tools you can use today — for personal use (1/3)” by @LiamHanel https://t.co/E6zDq7W5gY   [ Sat May 13 18:55:58 +0000 2017 ]\n",
      "===========================\n",
      "{\n",
      "    \"contributors\": null, \n",
      "    \"truncated\": false, \n",
      "    \"text\": \"RT @clubdedatos: \\u201cA list of artificial intelligence tools you can use today \\u2014 for personal use (1/3)\\u201d by @LiamHanel https://t.co/E6zDq7W5gY\", \n",
      "    \"is_quote_status\": false, \n",
      "    \"in_reply_to_status_id\": null, \n",
      "    \"id\": 863467874832273408, \n",
      "    \"favorite_count\": 0, \n",
      "    \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \n",
      "    \"retweeted\": false, \n",
      "    \"coordinates\": null, \n",
      "    \"timestamp_ms\": \"1494701758474\", \n",
      "    \"entities\": {\n",
      "        \"user_mentions\": [\n",
      "            {\n",
      "                \"id\": 261452842, \n",
      "                \"indices\": [\n",
      "                    3, \n",
      "                    15\n",
      "                ], \n",
      "                \"id_str\": \"261452842\", \n",
      "                \"screen_name\": \"clubdedatos\", \n",
      "                \"name\": \"Club de Datos\"\n",
      "            }, \n",
      "            {\n",
      "                \"id\": 57592622, \n",
      "                \"indices\": [\n",
      "                    105, \n",
      "                    115\n",
      "                ], \n",
      "                \"id_str\": \"57592622\", \n",
      "                \"screen_name\": \"LiamHanel\", \n",
      "                \"name\": \"Liam H\\u00e4nel\"\n",
      "            }\n",
      "        ], \n",
      "        \"symbols\": [], \n",
      "        \"hashtags\": [], \n",
      "        \"urls\": [\n",
      "            {\n",
      "                \"url\": \"https://t.co/E6zDq7W5gY\", \n",
      "                \"indices\": [\n",
      "                    116, \n",
      "                    139\n",
      "                ], \n",
      "                \"expanded_url\": \"https://hackernoon.com/a-list-of-artificial-intelligence-tools-you-can-use-today-for-personal-use-1-3-7f1b60b6c94f\", \n",
      "                \"display_url\": \"hackernoon.com/a-list-of-arti\\u2026\"\n",
      "            }\n",
      "        ]\n",
      "    }, \n",
      "    \"in_reply_to_screen_name\": null, \n",
      "    \"id_str\": \"863467874832273408\", \n",
      "    \"retweet_count\": 0, \n",
      "    \"in_reply_to_user_id\": null, \n",
      "    \"favorited\": false, \n",
      "    \"retweeted_status\": {\n",
      "        \"contributors\": null, \n",
      "        \"truncated\": false, \n",
      "        \"text\": \"\\u201cA list of artificial intelligence tools you can use today \\u2014 for personal use (1/3)\\u201d by @LiamHanel https://t.co/E6zDq7W5gY\", \n",
      "        \"is_quote_status\": false, \n",
      "        \"in_reply_to_status_id\": null, \n",
      "        \"id\": 863461847801974785, \n",
      "        \"favorite_count\": 1, \n",
      "        \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \n",
      "        \"retweeted\": false, \n",
      "        \"coordinates\": null, \n",
      "        \"entities\": {\n",
      "            \"user_mentions\": [\n",
      "                {\n",
      "                    \"id\": 57592622, \n",
      "                    \"indices\": [\n",
      "                        88, \n",
      "                        98\n",
      "                    ], \n",
      "                    \"id_str\": \"57592622\", \n",
      "                    \"screen_name\": \"LiamHanel\", \n",
      "                    \"name\": \"Liam H\\u00e4nel\"\n",
      "                }\n",
      "            ], \n",
      "            \"symbols\": [], \n",
      "            \"hashtags\": [], \n",
      "            \"urls\": [\n",
      "                {\n",
      "                    \"url\": \"https://t.co/E6zDq7W5gY\", \n",
      "                    \"indices\": [\n",
      "                        99, \n",
      "                        122\n",
      "                    ], \n",
      "                    \"expanded_url\": \"https://hackernoon.com/a-list-of-artificial-intelligence-tools-you-can-use-today-for-personal-use-1-3-7f1b60b6c94f\", \n",
      "                    \"display_url\": \"hackernoon.com/a-list-of-arti\\u2026\"\n",
      "                }\n",
      "            ]\n",
      "        }, \n",
      "        \"in_reply_to_screen_name\": null, \n",
      "        \"id_str\": \"863461847801974785\", \n",
      "        \"retweet_count\": 2, \n",
      "        \"in_reply_to_user_id\": null, \n",
      "        \"favorited\": false, \n",
      "        \"user\": {\n",
      "            \"follow_request_sent\": null, \n",
      "            \"profile_use_background_image\": true, \n",
      "            \"default_profile_image\": false, \n",
      "            \"id\": 261452842, \n",
      "            \"verified\": false, \n",
      "            \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/654389070232055808/8D7l_xAc_normal.png\", \n",
      "            \"profile_sidebar_fill_color\": \"FFFFFF\", \n",
      "            \"profile_text_color\": \"333333\", \n",
      "            \"followers_count\": 1190, \n",
      "            \"profile_sidebar_border_color\": \"EEEEEE\", \n",
      "            \"id_str\": \"261452842\", \n",
      "            \"profile_background_color\": \"ABB8C2\", \n",
      "            \"listed_count\": 229, \n",
      "            \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/654390457762381824/7ouTlzhw.png\", \n",
      "            \"utc_offset\": -18000, \n",
      "            \"statuses_count\": 136, \n",
      "            \"description\": \"Un nodo para quienes trabajan con datos y sus tecnolog\\u00edas: #DBMS #SQL #NoSQL #Infograf\\u00eda #OpenData #Analytics\", \n",
      "            \"friends_count\": 643, \n",
      "            \"location\": \"M\\u00e9xico\", \n",
      "            \"profile_link_color\": \"3B94D9\", \n",
      "            \"profile_image_url\": \"http://pbs.twimg.com/profile_images/654389070232055808/8D7l_xAc_normal.png\", \n",
      "            \"following\": null, \n",
      "            \"geo_enabled\": true, \n",
      "            \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/261452842/1444853719\", \n",
      "            \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/654390457762381824/7ouTlzhw.png\", \n",
      "            \"name\": \"Club de Datos\", \n",
      "            \"lang\": \"es\", \n",
      "            \"profile_background_tile\": true, \n",
      "            \"favourites_count\": 46, \n",
      "            \"screen_name\": \"clubdedatos\", \n",
      "            \"notifications\": null, \n",
      "            \"url\": null, \n",
      "            \"created_at\": \"Sun Mar 06 00:24:01 +0000 2011\", \n",
      "            \"contributors_enabled\": false, \n",
      "            \"time_zone\": \"Mexico City\", \n",
      "            \"protected\": false, \n",
      "            \"default_profile\": false, \n",
      "            \"is_translator\": false\n",
      "        }, \n",
      "        \"geo\": null, \n",
      "        \"in_reply_to_user_id_str\": null, \n",
      "        \"possibly_sensitive\": false, \n",
      "        \"lang\": \"en\", \n",
      "        \"created_at\": \"Sat May 13 18:32:01 +0000 2017\", \n",
      "        \"filter_level\": \"low\", \n",
      "        \"in_reply_to_status_id_str\": null, \n",
      "        \"place\": null\n",
      "    }, \n",
      "    \"user\": {\n",
      "        \"follow_request_sent\": null, \n",
      "        \"profile_use_background_image\": false, \n",
      "        \"default_profile_image\": false, \n",
      "        \"id\": 198599663, \n",
      "        \"verified\": false, \n",
      "        \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/836979492631490560/nvS-TjNh_normal.jpg\", \n",
      "        \"profile_sidebar_fill_color\": \"967EA0\", \n",
      "        \"profile_text_color\": \"372348\", \n",
      "        \"followers_count\": 1292, \n",
      "        \"profile_sidebar_border_color\": \"FFFFFF\", \n",
      "        \"id_str\": \"198599663\", \n",
      "        \"profile_background_color\": \"C0DEED\", \n",
      "        \"listed_count\": 198, \n",
      "        \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/378800000102954601/3ad84911c7836dfa7b566407cfd816cc.png\", \n",
      "        \"utc_offset\": 34200, \n",
      "        \"statuses_count\": 6211, \n",
      "        \"description\": \"Data enthusiast | tweets on: #energy #economics #OpenData #Latam #Ecuador #traveling | Colaboro en: @escueladedatos @schoolofdata @el_bid @datalat\", \n",
      "        \"friends_count\": 967, \n",
      "        \"location\": \"Latinoamerica\", \n",
      "        \"profile_link_color\": \"3B94D9\", \n",
      "        \"profile_image_url\": \"http://pbs.twimg.com/profile_images/836979492631490560/nvS-TjNh_normal.jpg\", \n",
      "        \"following\": null, \n",
      "        \"geo_enabled\": true, \n",
      "        \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/198599663/1487132585\", \n",
      "        \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/378800000102954601/3ad84911c7836dfa7b566407cfd816cc.png\", \n",
      "        \"name\": \"Julio L\\u00f3pez P.\", \n",
      "        \"lang\": \"es\", \n",
      "        \"profile_background_tile\": false, \n",
      "        \"favourites_count\": 3726, \n",
      "        \"screen_name\": \"jalp_ec\", \n",
      "        \"notifications\": null, \n",
      "        \"url\": null, \n",
      "        \"created_at\": \"Mon Oct 04 19:11:16 +0000 2010\", \n",
      "        \"contributors_enabled\": false, \n",
      "        \"time_zone\": \"Adelaide\", \n",
      "        \"protected\": false, \n",
      "        \"default_profile\": false, \n",
      "        \"is_translator\": false\n",
      "    }, \n",
      "    \"geo\": null, \n",
      "    \"in_reply_to_user_id_str\": null, \n",
      "    \"possibly_sensitive\": false, \n",
      "    \"lang\": \"en\", \n",
      "    \"created_at\": \"Sat May 13 18:55:58 +0000 2017\", \n",
      "    \"filter_level\": \"low\", \n",
      "    \"in_reply_to_status_id_str\": null, \n",
      "    \"place\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('ArtificialIntelligenceTweets.json', 'r') as f:\n",
    "    line = f.readline()\n",
    "    response_dict = json.loads(line) \n",
    "    # CAUTION: the user_timeline() and streaming sources do not produce the same structure of dictionary \n",
    "    #   when applying a json.loads() to either a json.dumps() or that of a Stream \n",
    "    # Use the \"encode late\" method with .encode('__') to properly interpret the string to print\n",
    "    print \"{}   [ {} ]\".format(response_dict['text'].encode('utf-8'),response_dict['created_at'])\n",
    "    print \"===========================\"\n",
    "    print(json.dumps(response_dict, indent=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'RT', u'@clubdedatos', u':', u'\\u201c', u'A', u'list', u'of', u'artificial', u'intelligence', u'tools', u'you', u'can', u'use', u'today', u'\\u2014', u'for', u'personal', u'use', u'(', u'1', u'/', u'3', u')', u'\\u201d', u'by', u'@LiamHanel', u'https://t.co/E6zDq7W5gY']\n",
      "[u'Can', u'Artificial', u'Intelligence', u'Replace', u'Executive', u'Decision', u'Making', u'?', u'via', u'@mitsmr', u'https://t.co/98wCa34v5m', u'#AI', u'#ML']\n",
      "[u'RT', u'@ograsl', u'Can', u'Artificial', u'Intelligence', u'Replace', u'Executive', u'Decision', u'Making', u'?', u'via', u'@mitsmr', u'https://t.co/msSosB0VIK', u'#AI', u'#ML']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'SmartLiving', u'or', u'as', u'we', u'might', u'live', u'with', u'artificial', u'intelligence', u'and', u'an', u'open', u'IoT', u'in', u'a', u'new', u'reality', u'|', u'#IoT', u'#Artificialin', u'\\u2026']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'SmartLiving', u'or', u'as', u'we', u'might', u'live', u'with', u'artificial', u'intelligence', u'and', u'an', u'open', u'IoT', u'in', u'a', u'new', u'reality', u'|', u'#IoT', u'#Artificialin', u'\\u2026']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'Why', u'Your', u'Company', u'Needs', u'Data', u'Translators', u'|', u'#Analytics', u'#Artificialintelligence', u'#RT', u'https://t.co/Zd8qxpCVXt', u'https://t.co/K', u'\\u2026']\n",
      "[u'In', u'2018', u'/', u'2019,', u'life', u'will', u'be', u'much', u'easier', u'with', u'Artificial', u'Intelligence', u'tech', u'.']\n",
      "[u'RT', u'@subhashishpaul', u':', u'#Amazon', u'\\u2019', u's', u'Echo', u'Look', u'is', u'a', u'minefield', u'of', u'#AI', u'and', u'privacy', u'concerns', u'https://t.co/5fefGzFBxR', u'#artificialintelligence']\n",
      "[u'RT', u'@evankirstel', u':', u'Why', u'we', u'must', u'prepare', u'for', u'the', u'rise', u'of', u'the', u'machines', u'https://t.co/T2VvIIBIw2']\n",
      "[u'Norwegian', u'.', u'AI', u'to', u'launch', u'\\u20ac', u'100', u'million', u'fund', u'to', u'invest', u'in', u'artificial', u'intelligence', u'https://t.co/Yi5QhuS8lT', u'via', u'\\u2026', u'https://t.co/FajZJG8X6S']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'Why', u'Your', u'Company', u'Needs', u'Data', u'Translators', u'|', u'#Analytics', u'#Artificialintelligence', u'#RT', u'https://t.co/Zd8qxpCVXt', u'https://t.co/K', u'\\u2026']\n",
      "[u'RT', u'@europestartup', u':', u'Norwegian', u'.', u'AI', u'to', u'launch', u'\\u20ac', u'100', u'million', u'fund', u'to', u'invest', u'in', u'artificial', u'intelligence', u'https://t.co/Yi5QhuS8lT', u'via', u'\\u2026']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'How', u'Big', u'Data', u'Is', u'Empowering', u'AI', u'and', u'Machine', u'Learning', u'at', u'Scale', u'|', u'#BigData', u'#Artificialintelligence', u'#RT', u'\\u2026']\n",
      "[u'RT', u'@homeAIinfo', u':', u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Apple', u'Just', u'Acquired', u'This', u'Litt', u'https://t.co/N9w7DVzV', u'\\u2026']\n",
      "[u'Here', u'\\u2019', u's', u'The', u'Unofficial', u'Silicon', u'Valley', u'Explainer', u'On', u'Artificial', u'Intelligence', u'https://t.co/2XSnAiu9xE']\n",
      "[u'artificial', u'intelligence', u'(', u'AI', u')', u'\\u4eba\\u5de5\\u77e5\\u80fd']\n",
      "[u'DUBIOUS', u'ARTIFICIAL', u'INTELLIGENCE', u'IN', u'THE', u'WATER', u'APPLE', u'JACKS', u'OF', u'HORSE', u'SEXT', u'QUANTUM', u'COMPUTING', u'CANADA', u'.', u'YOUR', u'TRAVEL', u'COMPANION', u'IS']\n",
      "[u'Perpetuating', u'Bias', u':', u'Why', u'We', u'Should', u'Think', u'Critically', u'About', u'Artificial', u'Intelligence', u'in', u'Marketing', u'https://t.co/zL3DUnqLel']\n",
      "[u'Advancing', u'sex', u'technologies', u'\"', u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Fortune', u'\"', u'https://t.co/cx8LCphWrQ']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'How', u'Big', u'Data', u'Is', u'Empowering', u'AI', u'and', u'Machine', u'Learning', u'at', u'Scale', u'|', u'#BigData', u'#Artificialintelligence', u'#RT', u'\\u2026']\n",
      "[u'RT', u'@MadelineAshby', u':', u'\"', u\"I'm\", u'not', u'afraid', u'OF', u'artificial', u'intelligence', u'.', u\"I'm\", u'afraid', u'FOR', u'artificial', u'intelligence', u'.', u'\"', u'-', u'-', u'@tinysubversions', u'@FIBERFestival']\n",
      "[u'RT', u'@evankirstel', u':', u'Why', u'we', u'must', u'prepare', u'for', u'the', u'rise', u'of', u'the', u'machines', u'https://t.co/T2VvIIBIw2']\n",
      "[u'Should', u'cashiers', u'be', u'humans', u'or', u'machines', u'?', u'https://t.co/q0yQdPD8dD', u'#robots', u'#robotics', u'#ArtificialIntelligence', u'#AI', u'#startup']\n",
      "[u'RT', u'@europestartup', u':', u'Norwegian', u'.', u'AI', u'to', u'launch', u'\\u20ac', u'100', u'million', u'fund', u'to', u'invest', u'in', u'artificial', u'intelligence', u'https://t.co/Yi5QhuS8lT', u'via', u'\\u2026']\n",
      "[u'Sentiment', u'Analysis', u'Symposium', u'2017', u'-', u'NYC', u',', u'June', u'27', u'+', u'28', u'https://t.co/QqJUWrCG7w', u'#MRX', u'#ArtificialIntelligence', u'\\u2026', u'https://t.co/kKjQkTTIGu']\n",
      "[u'Canada', u':', u'an', u'increasingly', u'appealing', u'alternative', u'for', u'Artificial', u'Intelligence', u'https://t.co/5IjWqpGuMO', u'@botler_ai', u'\\u2026', u'https://t.co/SHR4rhdMOB']\n",
      "[u'How', u'law', u'firms', u'have', u'been', u'pioneering', u'the', u'use', u'of', u'artificial', u'intelligence', u'.', u'#PredictiveCoding', u'#eDiscovery', u'#AI', u'\\u2026', u'https://t.co/VucZRexzhJ']\n",
      "[u'RT', u'@Bitcoin_Bullet', u':', u'https://t.co/ztqHIJqKl4', u'-', u\"Let's\", u'think', u'about', u'the', u'future', u'Artificial', u'Intelligence', u'-', u'The', u'Future', u'-', u'Ethics', u'on', u'AI', u'&', u'amp', u';', u'more', u'(', u'\\u2026']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'https://t.co/Ajaq8HgWKg', u'#ai', u'#ml', u'#dl']\n",
      "[u'Artificial', u'intelligence', u'may', u'not', u'be', u'that', u'great', u',', u'but', u'I', u'still', u'prefer', u'it', u'to', u'the', u\"world's\", u'natural', u'stupidity']\n",
      "[u'RT', u'@ivyleaguewriter', u':', u'Will', u'Artificial', u'Intelligence', u'Replace', u'Manual', u'Content', u'Creation', u'?', u'https://t.co/Jzl37dQjF6', u'https://t.co/oVaQV8MIUo']\n",
      "[u'Should', u'cashiers', u'be', u'humans', u'or', u'machines', u'?', u'https://t.co/RdGC4kV5eQ', u'#robots', u'#robotics', u'#ArtificialIntelligence', u'#AI', u'#startup']\n",
      "[u'Design', u'In', u'An', u'Age', u'of', u'Artificial', u'Intelligence', u'\\u2013', u'Startup', u'Grind', u'\\u2013', u'Medium', u'https://t.co/CB80WabQGj']\n",
      "[u'RT', u'@tprstly', u':', u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Fortune', u'https://t.co/I1U80INlFe', u'#ai', u'https://t.co/FiTiU', u'\\u2026']\n",
      "[u'#artificialintelligence', u'https://t.co/9fC0JKZSDN', u'Teaching', u'robots', u'to', u'teach', u'other', u'robots']\n",
      "[u'RT', u'@marcusborba', u':', u'How', u'Companies', u'Are', u'Already', u'Using', u'AI', u'https://t.co/T5kWBKId7x', u'#ArtificialIntelligence', u'#DataScience', u'#MachineLearning', u'#AI', u'https', u'\\u2026']\n",
      "[u'Ronald', u'van', u'Loon', u':', u'SmartLiving', u'or', u'as', u'we', u'might', u'live', u'with', u'artificial', u'intelligence', u'and', u'an', u'open', u'IoT', u'in', u'a', u'new', u'reality', u'|', u'#', u'\\u2026', u'https://t.co/lW8EgDuUrE']\n",
      "[u'RT', u'@wiomax', u':', u'#Bigdata', u'and', u'#machinelearning', u'make', u'compelling', u'argument', u'for', u'#CyberSecurity', u'https://t.co/pGOlN99cbD', u'#DataAnalytics', u'\\u2026']\n",
      "[u'Artificial', u'intelligence', u'may', u'not', u'be', u'that', u'great', u',', u'but', u'I', u'still', u'prefer', u'it', u'to', u'natural', u',', u'human', u'stupidity']\n",
      "[u'Microsoft', u'wants', u'you', u'to', u'make', u'cooler', u'videos', u'and', u'is', u'using', u'artificial', u'intelligence', u'to', u'help', u'-', u'CNBC', u'https://t.co/xUX2RMK0l8']\n",
      "[u'RT', u'@jlmico', u':', u'#Dubai', u'police', u'launch', u'#AI', u'that', u'can', u'spot', u'crimes', u'before', u'they', u'happen', u':', u'https://t.co/2rKBvnj0Lh', u'#BigData', u'#MachineLearning', u'#Artificial', u'\\u2026']\n",
      "[u'RT', u'@Lumidatum', u':', u'Can', u'you', u'trust', u'insights', u'from', u'#ArtificialIntelligence', u'?', u'https://t.co/LQu9w92tBH', u'#datascience', u'#MachineLearning', u'#CIO', u'#CMO']\n",
      "[u'A', u'Designer', u'\\u2019', u's', u'Guide', u'To', u'The', u'$', u'15', u'Billion', u'#ArtificialIntelligence', u'Industry', u'-', u'Artificial', u'Intelligence', u'https://t.co/iDLuqSXzrO']\n",
      "[u'RT', u'@AEMarling', u':', u'\\u201c', u'Real', u'stupidity', u'beats', u'artificial', u'intelligence', u'every', u'time', u'.', u'\\u201d', u'\\u2015', u'Terry', u'Pratchett']\n",
      "[u'RT', u'@KhalidHamdan0', u':', u'In', u'the', u'future', u',', u'#ArtificialIntelligence', u'will', u'build', u'on', u'adoption', u'enablers', u'to', u'unlock', u'faster', u',', u'smarter', u'&', u'amp', u';', u'more', u'intuitive', u'a', u'\\u2026']\n",
      "[u'RT', u'@CIOStraightTalk', u':', u'.', u'@wadhwa', u',', u'@CarnegieMellon', u':', u'\"', u'#AI', u'is', u'here', u'and', u'making', u'amazing', u'things', u'possible', u'\"', u'#StraightTalk', u'thoughts', u'@MissDestructo', u'?', u'ht', u'\\u2026']\n",
      "[u'Artificial', u'Intelligence', u'and', u'customer', u'experience', u'.', u'The', u'past', u',', u'present', u'and', u'future', u'according', u'to', u'@briansolis', u'\\u2026', u'https://t.co/atfeQZ0jml']\n",
      "[u'The', u'era', u'of', u'Artificial', u'Intelligence', u'is', u'here', u',', u'but', u'companies', u'must', u'combine', u'this', u'technology', u'with', u'business', u'expertise', u'https://t.co/tiqUca6JEG']\n",
      "[u'Perpetuating', u'Bias', u':', u'Why', u'We', u'Should', u'Think', u'Critically', u'About', u'Artificial', u'Intelligence', u'in', u'Marketing', u'#ai', u'\\u2026', u'https://t.co/GX3fxkR6eu']\n",
      "[u'#TheInterMind', u'says', u'Conscious', u'Light', u'is', u'Data', u'for', u'the', u'Conscious', u'Mind', u'.', u'https://t.co/BXfRQY5coW', u'#ArtificialIntelligence', u'#AI', u'#Consciousness']\n",
      "[u'\\u201c', u'Cheat', u'sheet', u'of', u'many', u'neural', u'network', u'architectures', u'{', u'#artificialintelligence', u'#deeplearning', u'#machinelearning', u'}', u'\\u2026', u'https://t.co/QaNiBRfqM4']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Fortune', u'#AIForEveryone', u'#IAParaTodos', u'https://t.co/KEoFUAwxe3']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'The', u'10', u'Algorithms', u'Machine', u'Learning', u'Engineers', u'Need', u'to', u'Know', u'|', u'#MachineLearning', u'#Artificialintelligence', u'#RT', u'\\u2026']\n",
      "[u'RT', u'@_bernardofn', u':', u'A', u'Designer', u'\\u2019', u's', u'Guide', u'To', u'The', u'$', u'15', u'Billion', u'#ArtificialIntelligence', u'Industry', u'-', u'Artificial', u'Intelligence', u'https://t.co/iDLuqSXzrO']\n",
      "[u'#AI', u'that', u'generalizes', u'from', u'a', u'situation', u\"it's\", u'been', u'trained', u'on', u'to', u'one', u'where', u'it', u\"hasn't\", u'.', u'What', u'could', u'go', u'wrong', u'?', u'https://t.co/6ihVkV7cWq']\n",
      "[u'RT', u'@AxelHohl', u':', u'Science', u'Fiction', u'Movies', u'aka', u'.', u'KI', u',', u'Matrix', u'oder', u'Klassiker', u'wie', u\"'\", u'Welt', u'am', u'Draht', u\"'\", u'waren', u'schon', u'nicht', u'\\xfcbel', u'.', u'.', u'.', u\"'\", u'hach', u',', u'das', u'gut', u'\\u2026']\n",
      "[u'Intelligent', u'Agents', u':', u'How', u'Artificial', u'Intelligence', u'Fits', u'Into', u'#CRO', u'https://t.co/xr7L44Z2xw', u'https://t.co/Tw2IfDQVSj']\n",
      "[u'RT', u'@Ronald_vanLoon', u':', u'How', u'Big', u'Data', u'Is', u'Empowering', u'AI', u'and', u'Machine', u'Learning', u'at', u'Scale', u'|', u'#BigData', u'#Artificialintelligence', u'#RT', u'\\u2026']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'https://t.co/GDnRgFp2xw', u'#ai', u'#ml', u'#dl']\n",
      "[u'RT', u'@GrowthHackerSMB', u':', u'Intelligent', u'Agents', u':', u'How', u'Artificial', u'Intelligence', u'Fits', u'Into', u'#CRO', u'https://t.co/xr7L44Z2xw', u'https://t.co/Tw2IfDQVSj']\n",
      "[u'RT', u'@FortuneMagazine', u':', u'Apple', u'just', u'acquired', u'this', u'little-known', u'artificial', u'intelligence', u'startup', u'https://t.co/ohG3IUskJ2', u'https://t.co/CR8bNkzDgR']\n",
      "[u'RT', u'@MikeQuindazzi', u':', u'\\u201c', u'Cheat', u'sheet', u'of', u'many', u'neural', u'network', u'architectures', u'{', u'#artificialintelligence', u'#deeplearning', u'#machinelearning', u'}', u'\\u2026']\n",
      "[u'RT', u'@MikeQuindazzi', u':', u'\\u201c', u'Cheat', u'sheet', u'of', u'many', u'neural', u'network', u'architectures', u'{', u'#artificialintelligence', u'#deeplearning', u'#machinelearning', u'}', u'\\u2026']\n",
      "[u'RT', u'@wef', u':', u'Artificial', u'intelligence', u'will', u'make', u'or', u'break', u'us', u'.', u\"Here's\", u'how', u'we', u'need', u'to', u'respond', u'https://t.co/vuAHd0FQom', u'#technology', u'https://t.co/vsWz', u'\\u2026']\n",
      "[u'RT', u'@MikeQuindazzi', u':', u'\\u201c', u'Cheat', u'sheet', u'of', u'many', u'neural', u'network', u'architectures', u'{', u'#artificialintelligence', u'#deeplearning', u'#machinelearning', u'}', u'\\u2026']\n",
      "[u'RT', u'@anabmap', u':', u'We', u'started', u'new', u'research', u'@webfoundation', u'on', u'artificial', u'intelligence', u'.', u'Are', u'you', u'or', u'anyone', u'you', u'know', u'working', u'on', u'#AI', u'in', u'#Kenya', u'?', u'Ping', u'@', u'\\u2026']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'https://t.co/OqgmXv1OEO']\n",
      "[u'RT', u'@Grocery_HQ', u':', u'This', u'artificial', u'intelligence', u'is', u'designed', u'to', u'bring', u'grocers', u'future', u'success', u'@pathovertech', u'.', u'https://t.co/Vwmtqw1Pm6', u'https://t.c', u'\\u2026']\n",
      "[u'RT', u'@HEbertKONLABS', u':', u'The', u'era', u'of', u'Artificial', u'Intelligence', u'is', u'here', u',', u'but', u'companies', u'must', u'combine', u'this', u'technology', u'with', u'business', u'expertise', u'https://t', u'\\u2026']\n",
      "[u'RT', u'@cloudpreacher', u':', u'#AI', u'revolution', u'in', u'#FinTech', u'to', u'transform', u'the', u'business', u'financing', u'market', u'!', u'#machinelearning', u'#bigdata', u'#ML', u'\\u2026']\n",
      "[u'RT', u'@evankirstel', u':', u'Why', u'we', u'must', u'prepare', u'for', u'the', u'rise', u'of', u'the', u'machines', u'https://t.co/T2VvIIBIw2']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Fortune', u'https://t.co/ruMOzRp14d']\n",
      "[u'Apple', u'Just', u'Acquired', u'This', u'Little-Known', u'Artificial', u'Intelligence', u'Startup', u'-', u'Fortune', u'https://t.co/asrJtTz849']\n",
      "[u'RT', u'@AEMarling', u':', u'\\u201c', u'Real', u'stupidity', u'beats', u'artificial', u'intelligence', u'every', u'time', u'.', u'\\u201d', u'\\u2015', u'Terry', u'Pratchett']\n",
      "[u'Replacing', u'a', u'human', u'worker', u'with', u'#ArtificialIntelligence', u'can', u'only', u'result', u'in', u'a', u'local', u'optimum', u'in', u'response', u'quality', u'.']\n",
      "[u'RT', u'@cloudpreacher', u':', u'#ArtificialIntelligence', u'algorithms', u'helping', u'machines', u'think', u':', u'Collaborative', u'Approach', u'#AI', u'Evolution', u'!', u'#ML', u'\\u2026']\n",
      "[u'RT', u'@MikeQuindazzi', u':', u'\\u201c', u'Cheat', u'sheet', u'of', u'many', u'neural', u'network', u'architectures', u'{', u'#artificialintelligence', u'#deeplearning', u'#machinelearning', u'}', u'\\u2026']\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [<>]?\n",
    "        [:;=8]                          # eyes\n",
    "        [\\-o\\*\\'-]?                     # optional nose\n",
    "        [\\)\\]\\(\\[dDpP/\\:\\>\\<\\}\\{@\\|\\\\]  # mouth\n",
    "        |\n",
    "        [\\)\\]\\(\\[dDpP/\\:\\>\\<\\}\\{@\\|\\\\]  # mouth\n",
    "        [\\-o\\*\\'-]?                     # optional nose\n",
    "        [:;=8]                          # eyes\n",
    "        [<>]?\n",
    "        |\n",
    "        <3                              # heart\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    # r'([\\w%\\.-]+@[a-zA-Z0-9\\.-]+\\.[a-zA-Z0-9\\.-]+)',   # email addresses #  a-zA-Z0-9_ instead of \\w\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    # ur'(?:\\b\\w+\\b)', # other words     #####  r'(?:[\\w_]+)'\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.UNICODE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    # return tokens_re.findall(s,re.UNICODE)\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        # tokens = [token.encode('utf-8') if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# import io\n",
    "# f=io.open('ArtificialIntelligenceTweets.json', 'r', encoding='utf8' )\n",
    "with open('ArtificialIntelligenceTweets.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # tweet = json.loads(line.decode('utf8'))\n",
    "        tokens = preprocess(tweet['text'])\n",
    "        print(tokens)\n",
    "        \n",
    "# test: used one accented (utf-8 code value > 127) character in \"priscillâ\" below. \n",
    "# Treatment remains faulty, despite using    # -*- coding: utf-8 -*-  at begining of code\n",
    "# because the (i) regex pattern for email no entiende de non-ASCII, (ii) the tokenize() function\n",
    "# does not handle non-ASCII satisfactorily. Example: \"dónde\" becomes the token \"u'd\\xf3nde'\". \n",
    "\n",
    "# tweet = '@Priscilla: Mañana será. #flat-world :-> email me at priscillâ.Presley%23@dodo.gmail.com, https://neverland.ut'\n",
    "# print(preprocess(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u':', 51), (u'RT', 43), (u'\\u2026', 37), (u'Artificial', 29), (u'Intelligence', 26)]\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "fname = 'ArtificialIntelligenceTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "   count_all = Counter()\n",
    "   for line in f:\n",
    "       tweet = json.loads(line)\n",
    "       # Create a list with all the terms\n",
    "       terms_all = [term for term in preprocess(tweet['text'])]\n",
    "       # Update the counter\n",
    "       count_all.update(terms_all)\n",
    "   print(count_all.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ckb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "… : 37\n",
      "Artificial : 29\n",
      "Intelligence : 26\n",
      "intelligence : 20\n",
      "artificial : 17\n",
      "\n",
      "Stop words in English:\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'rt', 'via', 'RT']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import operator \n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") # download the stopword corpus on our computer\n",
    "from collections import Counter\n",
    " \n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words(language) + punctuation + ['rt', 'via', 'RT']\n",
    "# añadir '…' above in stop list, does not suppress detection of that token. \n",
    " \n",
    "fname = 'ArtificialIntelligenceTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "    count_all = Counter()\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_stop = [term for term in preprocess(tweet['text']) if term not in stop]\n",
    "        count_all.update(terms_stop)\n",
    "    for word, index in count_all.most_common(5):\n",
    "        print '%s : %s' % (word, index)\n",
    "        \n",
    "print \"\\nStop words in {}:\\n\".format(language.capitalize()),stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ckb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "#AI : 14\n",
      "#ArtificialIntelligence : 10\n",
      "#machinelearning : 7\n",
      "#artificialintelligence : 7\n",
      "#RT : 6\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import operator \n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") # download the stopword corpus on our computer\n",
    "from collections import Counter\n",
    " \n",
    "fname = 'ArtificialIntelligenceTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "    count_all = Counter()\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_hash = [term for term in preprocess(tweet['text']) if term.startswith('#')]\n",
    "        count_all.update(terms_hash)\n",
    "    for word, index in count_all.most_common(5):\n",
    "        print '%s : %s' % (word, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ckb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "… : 37\n",
      "Artificial : 29\n",
      "Intelligence : 26\n",
      "intelligence : 20\n",
      "artificial : 17\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import operator \n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\") # download the stopword corpus on our computer\n",
    "from collections import Counter\n",
    " \n",
    "language = \"english\"\n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words(language) + punctuation + ['rt', 'via', 'RT']\n",
    "# añadir '…' above in stop list, does not suppress detection of that token. \n",
    " \n",
    "fname = 'ArtificialIntelligenceTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "    count_all = Counter()\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_stop =   terms_only = [term for term in preprocess(tweet['text']) \\\n",
    "                                     if term not in stop and not term.startswith(('#', '@'))]\n",
    "        # Mind the double brackets (( )) startswith() takes a tuple (not a list) if we pass a list of inputs.\n",
    "        count_all.update(terms_stop)\n",
    "    for word, index in count_all.most_common(5):\n",
    "        print '%s : %s' % (word, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
